{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p>Heavylight is a lightweight Python library that allows you to run heavy modeling workloads using a familiar recursive syntax.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install heavylight\n</code></pre> <p>Requires Python 3.8+</p>"},{"location":"#quick-example","title":"Quick example","text":"<p>Models are defined by subclassing from <code>heavylight.Model</code></p> <pre><code>from heavylight import Model\n\nclass Annuity(Model):\n    def t(self, t):\n        return t\n\n    def expected_claim(self, t):\n        return self.number_alive(t) * self.data[\"annuity_per_period\"]\n\n    def number_alive(self, t):\n        if t == 0:\n            return self.data[\"initial_policies\"]\n        else:\n            return self.number_alive(t - 1) - self.deaths(t - 1)\n\n    def deaths(self, t):\n        return self.number_alive(t) * self.mortality_rate(t)\n\n    def mortality_rate(self, t):\n        return self.basis[\"q_x\"](t)\n</code></pre> <p>We can define data as a dictionary (heavylight can use any storage mechanism)</p> <pre><code>policy_data = {\n    \"initial_policies\": 10,\n    \"annuity_per_period\": 55,\n}\n</code></pre> <p>We likely need a basis too, heavylight includes a <code>Table</code> class for storing tables, but for this example we will define a mortality function directly, and store it in a basis:</p> <pre><code>def q_x(t):\n    return 0.02*2.64**(0.04 * (t + 30)) + 0.002\n\nbasis = {\n    'q_x':q_x,\n}\n</code></pre> <p>Pulling it all together, we run a projection and store it in a variable <code>model</code></p> <pre><code>model = Annuity(data = policy_data,\n                basis = basis,\n                proj_len = 40,\n                )\n</code></pre> <p>We can query individual results:</p> <pre><code>model.expected_claim(5)\n</code></pre> <p>Output: <code>379.7484060121289</code></p> <p>We can view results as a DataFrame:</p> <pre><code>model_cashflows = model.df\nmodel_cashflows.head()\n</code></pre> <p>Output:</p> t deaths expected_claim mortality_rate number_alive 0 0 0.661143 550 0.0661143 10 1 1 0.641139 513.637 0.0686529 9.33886 2 2 0.620078 478.374 0.071292 8.69772 3 3 0.598033 444.27 0.0740356 8.07764 4 4 0.575091 411.378 0.0768878 7.47961"},{"location":"#loading-from-templates-examples","title":"Loading from Templates / Examples","text":"<p>Heavylight includes some examples - note that this function doesn't form part of the API and is subject to change.  These are purely to give an example of how to define models and tables, and are not for direct production use.</p> <pre><code>import heavylight\n\n# an example protection model\nheavylight.make_example(download_to_path='examples', example_name='protection')\n\n#\u00a0install a small minimal template\nheavylight.make_example(download_to_path='examples', example_name='template')\n</code></pre> <p>Once run, these will appear in the <code>examples</code> folder relative to where the script was run.</p> <p>The protection model contains three different ways of running it (single policy, using numpy arrays, and using numpy arrays with memory optimisation).  The folder also contains an Excel spreadsheet which replicates the calculation.</p>"},{"location":"storage_function/","title":"Storage function","text":"<pre><code>import numpy as np\nimport heavylight\n\nclass SimpleModel(heavylight.Model):\n\n    def __init__(self, initial_pols_if: np.ndarray, mortality_rate: float):\n        # storage_function determines what gets stored in the results DataFrame\n        super().__init__(storage_function=lambda results: np.round(np.sum(results), 3)) # customize how you aggregate results\n        self.initial_pols_if = initial_pols_if\n        self.mortality_rate = mortality_rate\n\n    def t(self, t):\n        return t\n\n    def num_pols_if(self, t):\n        if t == 0:\n            return self.initial_pols_if\n        return self.num_pols_if(t - 1) - self.pols_death(t - 1) # causes exponential time complexity if uncached\n\n    def pols_death(self, t):\n        return self.num_pols_if(t) * self.mortality_rate\n\n    def cashflow(self, t):\n        return self.num_pols_if(t) * 100\n\n    def v(self, t):\n        if t == 0:\n            return 1\n        return self.v(t - 1) / (1 + self.forward_rate(t))\n\n    def forward_rate(self, t):\n        return 0.04\n\n    def pv_cashflow(self, t):\n        return self.cashflow(t) * self.v(t)\n\n# start with 10 policies and constant mortality rate of .01\nsimple_model = SimpleModel(initial_pols_if=np.ones((10,)), mortality_rate=.01)\n# run the model for 5 timesteps\nsimple_model.RunModel(proj_len=5)\n# create a dataframe to store results\nresults = simple_model.ToDataFrame()\n</code></pre> <p>Results are a Pandas dataframe:</p> t num_pols_if cashflow forward_rate pols_death v pv_cashflow 0 10 1000 0.04 0.1 1 1000 1 9.9 990 0.04 0.099 0.962 951.923 2 9.801 980.1 0.04 0.098 0.925 906.158 3 9.703 970.299 0.04 0.097 0.889 862.592 4 9.606 960.596 0.04 0.096 0.855 821.121 5 9.51 950.99 0.04 0.095 0.822 781.645"},{"location":"tables/","title":"Tables","text":"<p>Heavylight is design to be modular, you can pick and choose which functionality you use.</p> <p>A core feature of actuarial models is the use of a variety of assumption tables, for example yield curves, mortality tables, lapse rates and expenses tables.</p> <p>Heavylight includes the <code>Table</code> class which provides both individual and vectorised lookups, and an opinionated format for loading tables from pandas dataframes, csv files and excel files.</p> <pre><code>from heavylight import Table\nimport pandas as pd\nimport numpy as np\n# typically you would import the table from a csv or other source\n\ndf = pd.DataFrame(\n  {'age|int': np.arange(18, 65)}\n)\ndf['values'] = df['age|int'] * 0.01\n\ntab = Table(df)\n\n# we can query a single value\nprint(tab[20])   # prints(0.20)\n\n# we can query multiple values at once using numpy arrays.\nrng = np.random.default_rng(seed=42)   # set up random number generator\nages = rng.integers(low=18, high=65, size=100_000, endpoint=True)   # sample 100k ages\nvals = tab[ages]    # query the table and store values\n</code></pre>"},{"location":"tables/#defining-column-types","title":"Defining Column Types","text":"<p><code>Table</code> determines the type of key column based on the column name suffix, the following are supported:</p> <ul> <li><code>|int</code>: integers (...0, 1, 2, 3...), can start and end anywhere, but must be consecutive</li> <li><code>|int_bound</code>: as <code>|int</code> but any values are constrained to the lowest and highest values.</li> <li><code>|int_cat</code>: integer are interpreted as categories, e.g. frequencies of 1, 3, 6, 12 months.</li> <li><code>|str</code>: keys are interpreted as strings, e.g. 'M' and 'F'</li> <li><code>|band</code>: key is numeric and treated as the upper bound on a lookup.</li> </ul>"},{"location":"tables/#mult-factor-tables","title":"Mult-factor tables","text":"<p>Tables aren't limited to a single key, and keys can take any of the above types.</p> <p>For examples, if a table <code>tab2</code> had headers <code>age|int</code> and <code>sex|str</code>, to look up the value for age <code>20</code> and sex <code>F</code>:</p> <pre><code>tab2[20, 'F']\n</code></pre> <p>This also works with by passing in numpy arrays of keys. <pre><code>ages = np.array([20, 25, 30, 22])\nsexs = np.array(['F', 'M', 'M', F])\ntab2[ages, sexs]\n</code></pre></p>"},{"location":"api/heavylight_Model/","title":"Model","text":""},{"location":"api/heavylight_Model/#heavylight.Model","title":"<code>heavylight.Model</code>","text":""},{"location":"api/heavylight_Model/#heavylight.Model.df","title":"<code>df</code>  <code>property</code>","text":"<p>return a pandas dataframe of all single parameter columns parameterised with <code>t</code></p>"},{"location":"api/heavylight_Model/#heavylight.Model.__init__","title":"<code>__init__(*, do_run=None, proj_len: int = 0, **kwargs)</code>","text":"<p>Base Class to subclass for user models.</p> <p>When the model is instanced it is run to proj_len, if non-zero.</p>"},{"location":"api/heavylight_Model/#heavylight.Model.__init__--parameters","title":"Parameters","text":"<ul> <li>proj_len: length of projection to run</li> </ul> <p>All variables/methods in user models should be lower case, using underscore as spaces.</p> Class level methods <p>RunModel(proj_len):   Run the model to proj_len.</p> Special user methods <p>BeforeRun(self):   If this is specified in the user model it called before the projection starts, e.g. to set up some specific variables</p> <p>AfterRun(self):   user method, called after Run is completed, e.g. can use to calculate NPVs of variables</p> <p>methods/variables to avoid: methods/variables starting with an underscore <code>_</code> are treated as internal.  You may break functionality if you create your own.</p>"},{"location":"api/heavylight_Model/#heavylight.Model.RunModel","title":"<code>RunModel(proj_len: int)</code>","text":"<p>Run the model if not already run.</p>"},{"location":"api/heavylight_Model/#heavylight.Model.RunModel--parameters","title":"Parameters","text":"<ul> <li>proj_len: length of projection to run</li> </ul>"},{"location":"api/heavylight_Model/#heavylight.Model.ToDataFrame","title":"<code>ToDataFrame(param='t')</code>","text":"<p>return a pandas dataframe of all single parameter columns</p>"},{"location":"api/heavylight_Model/#heavylight.Model.ToDataFrame--parameters","title":"Parameters","text":"<ul> <li>param: parameter to filter on.  Default: <code>t</code></li> </ul>"},{"location":"api/heavylight_Table/","title":"Table","text":""},{"location":"api/heavylight_Table/#heavylight.Table","title":"<code>heavylight.Table</code>","text":"<p>Table provides multi-key compatible high performance table lookup.</p>"},{"location":"api/heavylight_Table/#heavylight.Table.__init__","title":"<code>__init__(df: pd.DataFrame, rectify: Union[bool, None] = False, safe: Union[bool, None] = True)</code>","text":"<p>Initialise a table from a dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>the pandas dataframe used to initialise the table</p> required <code>rectify</code> <code>Union[bool, None]</code> <p>force table to be rectangular (default False)</p> <code>False</code> <code>safe</code> <code>Union[bool, None]</code> <p>validates that integers are between bounds (default True)</p> <code>True</code> Tables should be in long format <ul> <li>the final column containing the values to look up</li> <li>all other columns contain keys to lookup</li> <li>tables should be contingous, i.e. no gaps in integer keys.</li> <li>tables should be complete if viewed as square matrixes (i.e. all combinations of keys are input).  If not, you should fill any gaps with np.nan or a suitable value.</li> </ul> <p>The type of key is determined by the suffix on the dataframe <code>df</code> column names: <code>|int</code>: integers (...0, 1, 2, 3...), can start and end anywhere, but must be consecutive <code>|int_bound</code>: as <code>|int</code> but any values are constrained to the lowest and highest values. <code>|int_cat</code>: as |str, categorical integers. <code>|str': keys are interpreted as strings, e.g. 'M' and 'F'</code>|band<code>: key is numeric and treated as the upper bound on a lookup.</code>|float`: not currently available due to floating point equality, use int or band depending on use case.</p>"},{"location":"api/heavylight_Table/#heavylight.Table.rectify","title":"<code>rectify(df: pd.DataFrame, fill=np.nan) -&gt; pd.DataFrame</code>  <code>staticmethod</code>","text":"<p>Convert a triangular (incomplete) dataframe into a valid rectangular dataframe</p> <p>any missing points will be filled with <code>fill</code>, default: np.nan</p>"},{"location":"api/heavylight_Table/#heavylight.Table.read_excel","title":"<code>read_excel(spreadsheet_path, sheet_name)</code>  <code>classmethod</code>","text":"<p>Read in a table from an excel sheet, for more control pass in the dataframe using <code>__init__</code></p>"},{"location":"api/heavylight_Table/#heavylight.Table.read_csv","title":"<code>read_csv(csv_path)</code>  <code>classmethod</code>","text":"<p>Read in a table from an csv file, for more control pass in the dataframe using <code>__init__</code></p>"},{"location":"api/lightmodel/","title":"LightModel","text":""},{"location":"api/lightmodel/#heavylight.LightModel","title":"<code>heavylight.LightModel</code>","text":"<p>Inheriting from this class causes functions starting with a lowercase letter to be cached.  The caches can be cleared to rerun the same instance with different data.  This model can be memory optimized to reduce the memory requirements of the model without impacting results or performance.</p>"},{"location":"api/lightmodel/#heavylight.LightModel.cache","title":"<code>cache</code>  <code>property</code>","text":"<p>This is the cache of the model. It is a dictionary of dictionaries.  The outer dictionary is keyed by the function name and the inner dictionary is keyed by the arguments.</p>"},{"location":"api/lightmodel/#heavylight.LightModel.cache_agg","title":"<code>cache_agg</code>  <code>property</code>","text":"<p>The <code>cache</code> property with the <code>agg_function</code> applied to the results.</p>"},{"location":"api/lightmodel/#heavylight.LightModel.df","title":"<code>df</code>  <code>property</code>","text":"<p>A dataframe with the <code>cache</code> values of all functions that have a single parameter <code>t</code>.</p>"},{"location":"api/lightmodel/#heavylight.LightModel.df_agg","title":"<code>df_agg</code>  <code>property</code>","text":"<p>The <code>df</code> property dataframe with the <code>agg_function</code> applied to the results.</p>"},{"location":"api/lightmodel/#heavylight.LightModel.__init__","title":"<code>__init__(agg_function: Union[Callable, None] = default_agg_function)</code>","text":"<p>Arguments</p> <p><code>agg_function</code>: Aggregation function for storing results. This function is applied to the return values of each method.  In memory optimized models the cache is cleared but the aggregated results are stored for reporting.   If <code>agg_function</code> is not provided, the default aggregation function is used.  If <code>agg_function</code> is <code>None</code>, no aggregated results will be provided unless overridden at a method level with <code>agg</code>.</p> <p>The implementation of the default aggregation function is as follows:</p> <pre><code>def default_agg_function(x: Any):\n    if isinstance(x, np.ndarray) and issubclass(x.dtype.type, np.number):\n        return np.sum(x)\n    return x\n</code></pre>"},{"location":"api/lightmodel/#heavylight.LightModel.RunModel","title":"<code>RunModel(proj_len: int)</code>","text":"<p>Arguments</p> <ul> <li><code>proj_len</code>: Projection length. All single parameter timestep functions will be run for each timestep in <code>range(proj_len + 1)</code>.</li> </ul>"},{"location":"api/lightmodel/#heavylight.LightModel.Clear","title":"<code>Clear()</code>","text":"<p>Clears the cache. If the model was memory optimized, it is no longer memory optimized.</p>"},{"location":"api/lightmodel/#heavylight.LightModel.ClearOptimize","title":"<code>ClearOptimize()</code>","text":"<p>Clears the cache. The model is memory optimized after this function is called.</p>"},{"location":"api/lightmodel/#heavylight.agg","title":"<code>heavylight.agg(agg_function: Union[Callable, None])</code>","text":"<p>Register the storage function of a method.</p> <p>Used for storing aggregated results before cache eviction to reduce memory consumption.</p>"},{"location":"experiments/","title":"Experiments","text":"<p>This section of documentation contains experiments, demos etc.</p>"},{"location":"getting_started/heavylight_tables/","title":"Exploring heavylight.Tables","text":"In\u00a0[18]: Copied! <pre>from heavylight import Table\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport heavylight\nprint(f\"Version: {heavylight.__version__ = }\")\n</pre> from heavylight import Table import numpy as np import pandas as pd import seaborn as sns import heavylight print(f\"Version: {heavylight.__version__ = }\") <pre>Version: heavylight.__version__ = '1.0.10'\n</pre> In\u00a0[2]: Copied! <pre>df1 = pd.DataFrame({\n    'x|int': np.arange(20, 51),\n})\ndf1['value|float'] = df1['x|int'] * 0.04 - 0.03\ndf1.tail()\n</pre> df1 = pd.DataFrame({     'x|int': np.arange(20, 51), }) df1['value|float'] = df1['x|int'] * 0.04 - 0.03 df1.tail() Out[2]: x|int value|float 26 46 1.81 27 47 1.85 28 48 1.89 29 49 1.93 30 50 1.97 <p>We can pass the dataframe in as the contructor to the class.</p> In\u00a0[3]: Copied! <pre>tab1 = Table(df1)\n</pre> tab1 = Table(df1) <p>Querying a single value from the table just involves using array <code>[]</code> notation.</p> In\u00a0[4]: Copied! <pre>print(tab1[20])\nprint(tab1[20] - (20*0.04 - 0.03))    # this should equal zero\n</pre> print(tab1[20]) print(tab1[20] - (20*0.04 - 0.03))    # this should equal zero <pre>0.77\n0.0\n</pre> <p>We can query multiple results by passing in a numpy array.  (if not a numpy array then convert first using <code>np.array</code>).</p> In\u00a0[5]: Copied! <pre>x1s = np.array([30, 20, 20, 50])\ntab1[x1s]\n</pre> x1s = np.array([30, 20, 20, 50]) tab1[x1s] Out[5]: <pre>array([1.17, 0.77, 0.77, 1.97])</pre> In\u00a0[6]: Copied! <pre>df2 = pd.DataFrame(\n    {\n        'x|str':['A', 'B', 'C'],\n        'value|float': [0.3, 0.5, 0.9]\n    }\n)\ndf2\n</pre> df2 = pd.DataFrame(     {         'x|str':['A', 'B', 'C'],         'value|float': [0.3, 0.5, 0.9]     } ) df2 Out[6]: x|str value|float 0 A 0.3 1 B 0.5 2 C 0.9 In\u00a0[7]: Copied! <pre>tab2 = Table(df2)\n</pre> tab2 = Table(df2) In\u00a0[8]: Copied! <pre>tab2['A']\n</pre> tab2['A'] Out[8]: <pre>0.3</pre> In\u00a0[9]: Copied! <pre>tab2['B']\n</pre> tab2['B'] Out[9]: <pre>0.5</pre> <p>Warning: Note that the string lookup implementation currently uses a binary insertion algorithm, this means that you may get a false positive if you query a non-existent string.   For string lookups you should ensure you have validated data for consistency with assumptions, or consider converting to using integer keys for categories.  (e.g. <code>Male</code> -&gt; 0, <code>Female</code> -&gt; 1)</p> <p>This may be fixed in a future version of heavylight.</p> In\u00a0[17]: Copied! <pre>try:\n    tab2['AB']   # key doesn't exist\nexcept KeyError as err:\n    print(repr(err))\n</pre> try:     tab2['AB']   # key doesn't exist except KeyError as err:     print(repr(err)) <pre>KeyError('invalid string key(s) passed into table lookup.')\n</pre> <p>Again, we can lookup up an array of keys and obtain an array of values.</p> In\u00a0[\u00a0]: Copied! <pre>x2s = np.array(['A', 'A', 'C', 'B'])\ntab2[x2s]\n</pre> x2s = np.array(['A', 'A', 'C', 'B']) tab2[x2s] Out[\u00a0]: <pre>array([0.3, 0.3, 0.9, 0.5])</pre> <p>Note that if the key doesn't exist and it is greater than the largest value, then an error will correctly be returned.</p> In\u00a0[\u00a0]: Copied! <pre>try:\n    tab2['Z']\nexcept Exception as err:\n    print(repr(err))\n</pre> try:     tab2['Z'] except Exception as err:     print(repr(err)) <pre>IndexError('index 3 is out of bounds for axis 0 with size 3')\n</pre> In\u00a0[\u00a0]: Copied! <pre>df3 = pd.DataFrame({\n    'age_to|band': np.array([20, 30, 40, 60, 90, 130, np.inf]),\n})\ndf3['value|str'] = df3['age_to|band'].map(lambda i: f'age_to_{i:03.0f}')\ndf3\n</pre> df3 = pd.DataFrame({     'age_to|band': np.array([20, 30, 40, 60, 90, 130, np.inf]), }) df3['value|str'] = df3['age_to|band'].map(lambda i: f'age_to_{i:03.0f}') df3 Out[\u00a0]: age_to|band value|str 0 20.0 age_to_020 1 30.0 age_to_030 2 40.0 age_to_040 3 60.0 age_to_060 4 90.0 age_to_090 5 130.0 age_to_130 6 inf age_to_inf <p>Create a table (again, passing the dataframe in is sufficient)</p> In\u00a0[\u00a0]: Copied! <pre>tab3 = Table(df3)\n</pre> tab3 = Table(df3) <p>We can look up any floating point value, and it will return the band it is contained within:</p> In\u00a0[\u00a0]: Copied! <pre>tab3[18.5]\n</pre> tab3[18.5] Out[\u00a0]: <pre>'age_to_020'</pre> In\u00a0[\u00a0]: Copied! <pre>tab3[20]\n</pre> tab3[20] Out[\u00a0]: <pre>'age_to_020'</pre> In\u00a0[\u00a0]: Copied! <pre>tab3[20.00000001]\n</pre> tab3[20.00000001] Out[\u00a0]: <pre>'age_to_030'</pre> In\u00a0[\u00a0]: Copied! <pre># there is no lower bound (generally because the bands will be currency)\ntab3[-5]\n</pre> # there is no lower bound (generally because the bands will be currency) tab3[-5] Out[\u00a0]: <pre>'age_to_020'</pre> In\u00a0[\u00a0]: Copied! <pre># there is an upper bound, and will error if over this\ntry:\n    print(tab3[131])\nexcept Exception as err:\n    print(repr(err))\n</pre> # there is an upper bound, and will error if over this try:     print(tab3[131]) except Exception as err:     print(repr(err)) <pre>age_to_inf\n</pre> In\u00a0[\u00a0]: Copied! <pre>x3s = np.linspace(35, 45, 14)\npd.DataFrame({'x3s':x3s, 'result':tab3[x3s]})\n</pre> x3s = np.linspace(35, 45, 14) pd.DataFrame({'x3s':x3s, 'result':tab3[x3s]}) Out[\u00a0]: x3s result 0 35.000000 age_to_040 1 35.769231 age_to_040 2 36.538462 age_to_040 3 37.307692 age_to_040 4 38.076923 age_to_040 5 38.846154 age_to_040 6 39.615385 age_to_040 7 40.384615 age_to_060 8 41.153846 age_to_060 9 41.923077 age_to_060 10 42.692308 age_to_060 11 43.461538 age_to_060 12 44.230769 age_to_060 13 45.000000 age_to_060 In\u00a0[\u00a0]: Copied! <pre>df4 = pd.DataFrame({\n    'term|int_bound': [5, 6, 7, 8, 9, 10],\n    'rate': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1],\n})\ndf4\n</pre> df4 = pd.DataFrame({     'term|int_bound': [5, 6, 7, 8, 9, 10],     'rate': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1], }) df4 Out[\u00a0]: term|int_bound rate 0 5 0.05 1 6 0.06 2 7 0.07 3 8 0.08 4 9 0.09 5 10 0.10 In\u00a0[\u00a0]: Copied! <pre>tab4 = Table(df4)\n</pre> tab4 = Table(df4) In\u00a0[\u00a0]: Copied! <pre>x4s = np.arange(0, 15)\nsns.lineplot(x=x4s, y=tab4[x4s], markers=True)\n</pre> x4s = np.arange(0, 15) sns.lineplot(x=x4s, y=tab4[x4s], markers=True) Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>df5 = pd.DataFrame({\n    'age|int_bound': np.tile(np.arange(20, 41), 5),\n    'dur|int_bound': np.repeat(np.arange(1, 6), (41-20))\n})\ndf5['values'] = df5['age|int_bound'] * 0.01 + 1.32 ** df5['dur|int_bound']\ndf5\n</pre> df5 = pd.DataFrame({     'age|int_bound': np.tile(np.arange(20, 41), 5),     'dur|int_bound': np.repeat(np.arange(1, 6), (41-20)) }) df5['values'] = df5['age|int_bound'] * 0.01 + 1.32 ** df5['dur|int_bound'] df5 Out[\u00a0]: age|int_bound dur|int_bound values 0 20 1 1.520000 1 21 1 1.530000 2 22 1 1.540000 3 23 1 1.550000 4 24 1 1.560000 ... ... ... ... 100 36 5 4.367464 101 37 5 4.377464 102 38 5 4.387464 103 39 5 4.397464 104 40 5 4.407464 <p>105 rows \u00d7 3 columns</p> In\u00a0[\u00a0]: Copied! <pre>tab5 = Table(df5)\n</pre> tab5 = Table(df5) <p>We can lookup the keys by passing in comma separated values</p> In\u00a0[\u00a0]: Copied! <pre>tab5[104, 40]\n</pre> tab5[104, 40] Out[\u00a0]: <pre>4.4074642432000015</pre> <p>Like the one dimensional case, we can pass in numpy arrays of values to each key, to obtain an array of results:</p> In\u00a0[\u00a0]: Copied! <pre>x5_age = np.array([20, 20, 40, 30, 0, 9999])\nx5_dur = np.array([1, 2, 3, 5, -2, 9999])\ntab5[x5_age, x5_dur]\n</pre> x5_age = np.array([20, 20, 40, 30, 0, 9999]) x5_dur = np.array([1, 2, 3, 5, -2, 9999]) tab5[x5_age, x5_dur] Out[\u00a0]: <pre>array([1.52      , 1.9424    , 2.699968  , 4.30746424, 1.52      ,\n       4.40746424])</pre> In\u00a0[\u00a0]: Copied! <pre>df6 = pd.DataFrame({\n    'k1|int': [1, 2, 3, 4, 1, 2],\n    'k2|str': list('AAAABB'),\n    'values': [1, 2, 3, 4, 11, 22]\n})\ndf6\n</pre> df6 = pd.DataFrame({     'k1|int': [1, 2, 3, 4, 1, 2],     'k2|str': list('AAAABB'),     'values': [1, 2, 3, 4, 11, 22] }) df6 Out[\u00a0]: k1|int k2|str values 0 1 A 1 1 2 A 2 2 3 A 3 3 4 A 4 4 1 B 11 5 2 B 22 In\u00a0[\u00a0]: Copied! <pre># This will trigger a value error\n\ntry:\n    tab6 = Table(df6)\nexcept Exception as err:\n    print(repr(err))\n</pre> # This will trigger a value error  try:     tab6 = Table(df6) except Exception as err:     print(repr(err)) <pre>ValueError('Input `df` is not rectangular, expected_rows=8 != len(self.values)=6')\n</pre> <p>We can attempt ensure tables are rectangular by using the <code>rectify</code> parameter.  This may not work if the table is sufficiently complex.  In some cases you may prefer to split the table into several tables.</p> In\u00a0[\u00a0]: Copied! <pre>tab6b = Table(df6, rectify=True)\n</pre> tab6b = Table(df6, rectify=True) <p>Keys with values are looked up as expected:</p> In\u00a0[\u00a0]: Copied! <pre>tab6b[1, 'A']\n</pre> tab6b[1, 'A'] Out[\u00a0]: <pre>1.0</pre> <p>Keys which aren't specified (i.e. <code>3, 'B'</code> and <code>4, 'B'</code>) return <code>np.nan</code>:</p> In\u00a0[\u00a0]: Copied! <pre>tab6b[4, 'B']\n</pre> tab6b[4, 'B'] Out[\u00a0]: <pre>nan</pre> <p>Examples for the <code>read_csv</code> and <code>read_excel</code> methods are not included here, as they depend on the availability of suitable files.</p> In\u00a0[11]: Copied! <pre>df7 = pd.DataFrame({\n    'deferred_period|int_cat': [1, 4, 12, 26, 52],\n    'values|str': ['one week', 'one month', 'three months', 'six months', 'one year']\n})\ndf7\n</pre> df7 = pd.DataFrame({     'deferred_period|int_cat': [1, 4, 12, 26, 52],     'values|str': ['one week', 'one month', 'three months', 'six months', 'one year'] }) df7 Out[11]: deferred_period|int_cat values|str 0 1 one week 1 4 one month 2 12 three months 3 26 six months 4 52 one year In\u00a0[12]: Copied! <pre>tab7 = Table(df7)\n</pre> tab7 = Table(df7) In\u00a0[13]: Copied! <pre>tab7\n</pre> tab7 Out[13]: <pre>   deferred_period|int_cat    values|str\n0                        1      one week\n1                        4     one month\n2                       12  three months\n3                       26    six months\n4                       52      one year</pre> In\u00a0[14]: Copied! <pre>tab7[4]\n</pre> tab7[4] Out[14]: <pre>'one month'</pre> In\u00a0[16]: Copied! <pre>try:\n    tab7[5]\nexcept KeyError as err:\n    print(repr(err))\n</pre> try:     tab7[5] except KeyError as err:     print(repr(err)) <pre>KeyError('invalid integer category key(s) passed into table lookup.')\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"getting_started/heavylight_tables/#exploring-heavylighttables","title":"Exploring heavylight.Tables\u00b6","text":"<p>This document provides a walkthrough of <code>Table</code> features, including examples showing the dynamics.</p>"},{"location":"getting_started/heavylight_tables/#what-is-the-table-class","title":"What is the <code>Table</code> class?\u00b6","text":"<p>The Table class provides an efficient way to store and lookup values in actuarial tables, including tables with more than one key, and tables with interval based keys.  The table is stored in long format, that is, each unique key stores a single value.</p> <p>Using the <code>Table</code> is completely optional, and it can be used for other purposes as well as within heavylight Models.  You may find that Python dictionaries, classes, or pandas dataframes work better for certain use cases.  Challenges on use cases are welcome, please post a new issue on GitHub</p>"},{"location":"getting_started/heavylight_tables/#keys","title":"Keys\u00b6","text":"<p><code>Table</code> determines the type of key column based on the column name suffix, the following are supported:</p> <ul> <li><code>|int</code>: integers (...0, 1, 2, 3...), can start and end anywhere, but must be consecutive</li> <li><code>|int_bound</code>: as <code>|int</code> but any values are constrained to the lowest and highest values.</li> <li><code>|int_cat</code>: integer are interpreted as categories, e.g. frequencies of 1, 3, 6, 12 months.</li> <li><code>|str</code>: keys are interpreted as strings, e.g. 'M' and 'F'</li> <li><code>|band</code>: key is numeric and treated as the upper bound on a lookup.</li> </ul>"},{"location":"getting_started/heavylight_tables/#creating-a-table","title":"Creating a Table\u00b6","text":"<p>Below table has an example of the input structure for creating a table, which has 3 keys (age, dur, product) and one value:</p> age|int dur|int_bound product|str value|float 20 0 DTA 0.03 21 0 DTA 0.04 ... ... .... ... <p>Note that the <code>value</code> type (<code>|float</code>) is not currently used/implemented, however we recommend using this to document the type of the value, and if a future implementation includes value type validation.</p> <p>Tables are typically created from dataframes, for convenience a <code>read_excel</code> and <code>read_csv</code> methods are included which will work for correctly prepared tables.</p>"},{"location":"getting_started/heavylight_tables/#initialising-using-table","title":"Initialising using <code>Table()</code>\u00b6","text":"<pre>table = Table(df, rectify=False, safe=True)\n</pre> <p>This has the following arguments:</p> <ul> <li><p><code>df</code>: The pandas dataframe to be loaded in, which should follow the rules outlined above in terms of keys and values.  Any index columns in the dataframe will be ignored.</p> </li> <li><p>optional <code>rectify</code>: If <code>True</code> then this will attempt to ensure that the dataframe is rectangular, through filling out any missing values.  The default <code>False</code> will cause an error to be raised if the dataframe isn't rectangular.  A rectangular dataframe is one where a value is defined for each combination of keys in each of the key columns.</p> </li> <li><p>optional <code>safe</code>: If <code>True</code> then any <code>|int</code> keys will be automatically tested to ensure they are within the lower and upper bounds, with an exception being raised if any values fall outside the interval.  Keys of type <code>int_bound</code> are automatically safe.</p> </li> </ul>"},{"location":"getting_started/heavylight_tables/#initialising-using-tableread_excel-and-tableread_csv","title":"Initialising using <code>Table.read_excel</code> and <code>Table.read_csv</code>\u00b6","text":"<pre>Table.read_excel(spreadsheet_path, sheet_name)\n</pre> <p>This has the following arguments:</p> <ul> <li><code>spreadsheet_path</code>: a string or pathlib.Path object pointing to the spreadsheet, for example: <code>C:\\path\\to\\basis.xlsx</code></li> <li><code>sheet_name</code>: the name of the worksheet within the workbook, for example: <code>mortality_table</code>.  <code>read_excel</code> will attempt to read all data in this sheet to the table.</li> </ul> <p>If you have more complicated spreadsheets (for example offset/named ranges), you may need to write your own reader to prepare the dataframe and use the <code>Table()</code> constructor.</p> <p>You may need to install <code>openpyxl</code> or another python Excel library in order to use this constructor.</p> <pre>Table.read_csv(csv_path)\n</pre> <p>This will aim to create a dataframe by using <code>pandas.read_csv</code>.  For more complicated csv files, including non-standard separators, using <code>pandas.read_&lt;type&gt;</code> is recommended.</p> <p>This has the following argument:</p> <ul> <li><code>csv_path</code>: the path to the csv file.</li> </ul> <p>The following examples are intended to illustrate the above.</p>"},{"location":"getting_started/heavylight_tables/#example-1-simple-table","title":"Example 1: Simple Table\u00b6","text":"<p>Tables can be created directly from pandas dataframes, or from csv files or excel spreadsheet.</p> <p>Here we create a dataframe table, with key <code>x</code> being an integer key, and floating point values.</p>"},{"location":"getting_started/heavylight_tables/#example-2-string-key","title":"Example 2: String key\u00b6","text":""},{"location":"getting_started/heavylight_tables/#example-3-banded-key","title":"Example 3: Banded Key\u00b6","text":"<p>Often we may want to get a value for a range of inputs, for example if a fee applies to a range of fund values, or reinsurance rates are set by sum assured bands.</p> <p>We can assign one or more band tables using the <code>|band</code> suffix, which specifies the upper bound for that band.</p> <p>The interval is open on the left, closed on the right, i.e. $(B-1, B]$ with the first band being $[-\\infty, B]$.  For an open ended final band, <code>np.inf</code> or a significantly high number should be chosen.</p>"},{"location":"getting_started/heavylight_tables/#example-4-bounded-integer","title":"Example 4: Bounded Integer\u00b6","text":"<p>If we are dealing with integer keys, sometimes we want the last key to be used for all higher values, for example in a mortality table with a 5 year select period, for durations 5+ we want to use the 5 year duration rate.  This can be accomplished by specifying the key column as a bounded integer: <code>|int_bound</code>.  When specified, this applies both on the lower and upper bounds.</p>"},{"location":"getting_started/heavylight_tables/#example-5-two-keys-are-better-than-one","title":"Example 5: Two keys are better than one\u00b6","text":"<p>Tables often have multiple dimensions, e.g. Income Protection recovery rates vary by age, duration etc.  <code>Table</code> deals with these the same way as the one dimensional case.</p>"},{"location":"getting_started/heavylight_tables/#example-6-error-tables-need-to-be-complete","title":"Example 6: Error: Tables need to be complete\u00b6","text":"<p>If using more than one dimension, the table needs to be complete, i.e. len(key 1) x len(key 2) x len(key 3) == len(table).</p> <p>This is tested at table construction time.</p>"},{"location":"getting_started/heavylight_tables/#example-7-integer-category-keys","title":"Example 7: Integer Category Keys\u00b6","text":"<p>Added in v1.0.10.  <code>|int</code> and <code>|int_bound</code> both assume integer keys are consecutive integers.  <code>int_cat</code> allows for arbitrary integer keys.  This is likely slower to evaluate, so it may be worthwhile considering encoding to integers directly, particularly as categories are all likely to be fed from data.  (e.g. 4,6,10 -&gt; 0, 1, 2)</p>"},{"location":"getting_started/intro_to_heavylight/","title":"An Introduction to Actuarial Modelling With Heavylight","text":"In\u00a0[1]: Copied! <pre>import heavylight\nimport pandas as pd\nimport numpy as np\nprint(f\"Version: {heavylight.__version__ = }\")\n</pre> import heavylight import pandas as pd import numpy as np print(f\"Version: {heavylight.__version__ = }\") <pre>Version: heavylight.__version__ = '1.0.10'\n</pre> In\u00a0[2]: Copied! <pre>class Model1(heavylight.Model):\n    def t(self, t):\n        \"\"\"time\"\"\"\n        return t\n    \n    def num_alive(self, t):\n        \"\"\"probability that life is alive at time t, given alive at time 0\"\"\"\n        if t == 0:\n            return 1\n        else:\n            return self.num_alive(t - 1) * 0.99\n</pre> class Model1(heavylight.Model):     def t(self, t):         \"\"\"time\"\"\"         return t          def num_alive(self, t):         \"\"\"probability that life is alive at time t, given alive at time 0\"\"\"         if t == 0:             return 1         else:             return self.num_alive(t - 1) * 0.99 <p>We can quickly test the model runs by creating an instance of it, and assign it to the variable <code>model1</code>.  When an model is instanced, it is run as well, with the variable <code>proj_len</code> controlling how many time periods it is run for.  As Python uses zero-indexing this runs from 0, i.e. <code>proj_len = 5</code> will calculate for t = 0, 1, 2, 3, 4.</p> <p>Once the model has run, we can view the results as a dataframe using the <code>.df</code> property.</p> In\u00a0[3]: Copied! <pre>model1 = Model1(proj_len = 5)\nmodel1.df\n</pre> model1 = Model1(proj_len = 5) model1.df Out[3]: t num_alive 0 0 1.000000 1 1 0.990000 2 2 0.980100 3 3 0.970299 4 4 0.960596 In\u00a0[4]: Copied! <pre>model1.num_alive.values\n</pre> model1.num_alive.values Out[4]: <pre>[1, 0.99, 0.9801, 0.9702989999999999, 0.96059601]</pre> <p>Likewise, we can sum up all of them (in this case it's not too meaningful as we aren't looking at cashflows yet!)</p> In\u00a0[5]: Copied! <pre>model1.num_alive.sum()\n</pre> model1.num_alive.sum() Out[5]: <pre>4.90099501</pre> <p>We can obtain individual values by calling them with the appropriate parameter (<code>t</code> in this case)</p> In\u00a0[6]: Copied! <pre>model1.num_alive(4)\n</pre> model1.num_alive(4) Out[6]: <pre>0.96059601</pre> <p>We can view a dataframe just of the variables results.  This isn't that useful when the function is only dependent on t, however if we have functions with multiple keys such as both <code>t</code> and <code>duration</code>, then we can view all the output.</p> In\u00a0[7]: Copied! <pre>model1.num_alive.df\n</pre> model1.num_alive.df Out[7]: t num_alive 0 0 1.000000 1 1 0.990000 2 2 0.980100 3 3 0.970299 4 4 0.960596 <p>Running the projection to time 4 doesn't mean we can't obtain further values, it just means they aren't precomputed (and in extreme cases you may get a recursion limit or stack overflow error).  We can query any value by calling it.</p> In\u00a0[8]: Copied! <pre>model1.num_alive(20)\n</pre> model1.num_alive(20) Out[8]: <pre>0.8179069375972307</pre> <p>This computes all the intermediate values - we can check this in the dataframe.</p> <p>Note: the variable <code>t</code> hasn't been calculated for t &gt; 4, this is because the value of <code>t</code> has never been requested for t &gt; 4, as the <code>t(t)</code> method isn't called by <code>num_alive</code>.</p> In\u00a0[9]: Copied! <pre>model1.df\n</pre> model1.df Out[9]: t num_alive 0 0 1.000000 1 1 0.990000 2 2 0.980100 3 3 0.970299 4 4 0.960596 In\u00a0[10]: Copied! <pre>class Model2(heavylight.Model):\n    def t(self, t):\n        \"\"\"time\"\"\"\n        return t\n    \n    def num_alive(self, t):\n        \"\"\"probability that life is alive at time t, given alive at time 0\"\"\"\n        if t == 0:\n            return 1\n        else:\n            return self.num_alive(t - 1) - self.num_deaths(t - 1)     # deaths moved to a separate method\n        \n    def num_deaths(self, t):\n        \"\"\"number of deaths occuring between time t-1 and t\"\"\"\n        if t &lt; 0:\n            return 0\n        else:\n            q_x = 0.001 * self.age(t)\n            return self.num_alive(t) * q_x\n\n    def age(self, t):\n        \"\"\"age in years at time t\"\"\"\n        if t == 0:\n            return self.data[\"init_age\"]\n        elif t % 12 == 0:\n            return self.age(t - 1) + 1\n        else:\n            return self.age(t - 1)\n</pre> class Model2(heavylight.Model):     def t(self, t):         \"\"\"time\"\"\"         return t          def num_alive(self, t):         \"\"\"probability that life is alive at time t, given alive at time 0\"\"\"         if t == 0:             return 1         else:             return self.num_alive(t - 1) - self.num_deaths(t - 1)     # deaths moved to a separate method              def num_deaths(self, t):         \"\"\"number of deaths occuring between time t-1 and t\"\"\"         if t &lt; 0:             return 0         else:             q_x = 0.001 * self.age(t)             return self.num_alive(t) * q_x      def age(self, t):         \"\"\"age in years at time t\"\"\"         if t == 0:             return self.data[\"init_age\"]         elif t % 12 == 0:             return self.age(t - 1) + 1         else:             return self.age(t - 1) <p>We pass the data in as pass of the model instance creation, using the key <code>data</code> means it is accessible as <code>self.data</code> within the model, in our case <code>self.data['init_age']</code> will  look up init_age in the dictionary and return <code>32</code>.</p> In\u00a0[11]: Copied! <pre>data2 = dict(init_age = 32)\nmodel2 = Model2(data=data2, proj_len=10*12 + 1)\nmodel2.df\n</pre> data2 = dict(init_age = 32) model2 = Model2(data=data2, proj_len=10*12 + 1) model2.df Out[11]: t num_alive num_deaths age 0 0 1.000000 0.032000 32 1 1 0.968000 0.030976 32 2 2 0.937024 0.029985 32 3 3 0.907039 0.029025 32 4 4 0.878014 0.028096 32 ... ... ... ... ... 116 116 0.013636 0.000559 41 117 117 0.013077 0.000536 41 118 118 0.012541 0.000514 41 119 119 0.012027 0.000493 41 120 120 0.011534 0.000484 42 <p>121 rows \u00d7 4 columns</p> <p>We've got more data here to look at now, as <code>.df</code> outputs a pandas dataframe, we can access all the normal dataframe features, for example <code>.plot()</code> gives us access to the plotting interface.</p> In\u00a0[12]: Copied! <pre>model2.df.plot(x='t', y='num_alive');\n</pre> model2.df.plot(x='t', y='num_alive'); In\u00a0[13]: Copied! <pre>df_mort = pd.DataFrame(\n    {'age|int_bound': range(16, 131)}\n)\ndf_mort\n</pre> df_mort = pd.DataFrame(     {'age|int_bound': range(16, 131)} ) df_mort Out[13]: age|int_bound 0 16 1 17 2 18 3 19 4 20 ... ... 110 126 111 127 112 128 113 129 114 130 <p>115 rows \u00d7 1 columns</p> <p>Our table also need values (mortality rates).  Mortality rates are generally exponential, so we'll populate <code>q_x</code> using an exponential function - this has just been picked for ease of use:</p> <p>$q_x = 0.002e^{0.064(x-30)} + 0.001$</p> <p>We also use <code>np.clip</code> to ensure this falls in the range $[0, 1]$ as it is a probability.</p> In\u00a0[14]: Copied! <pre># 0.02*2.64**(0.04 * (t + 30)) + 0.002\ndf_mort['q_x|float'] = 0.002 * np.exp(0.064 * (df_mort['age|int_bound'] - 30)) + 0.001\ndf_mort['q_x|float'] = np.clip(df_mort['q_x|float'], 0, 1) # ensure between 0 and 1\ndf_mort\n</pre> # 0.02*2.64**(0.04 * (t + 30)) + 0.002 df_mort['q_x|float'] = 0.002 * np.exp(0.064 * (df_mort['age|int_bound'] - 30)) + 0.001 df_mort['q_x|float'] = np.clip(df_mort['q_x|float'], 0, 1) # ensure between 0 and 1 df_mort Out[14]: age|int_bound q_x|float 0 16 0.001816 1 17 0.001870 2 18 0.001928 3 19 0.001989 4 20 0.002055 ... ... ... 110 126 0.932827 111 127 0.994414 112 128 1.000000 113 129 1.000000 114 130 1.000000 <p>115 rows \u00d7 2 columns</p> <p>Let's check how that looks with a plot:</p> In\u00a0[15]: Copied! <pre>df_mort.plot(x='age|int_bound', y='q_x|float');\n</pre> df_mort.plot(x='age|int_bound', y='q_x|float'); <p>This looks fine, so we can create a heavylight <code>Table</code> instance using it.</p> In\u00a0[16]: Copied! <pre>mort_table = heavylight.Table(df_mort)\n</pre> mort_table = heavylight.Table(df_mort) <p>Tables are looked up based on keys, using the square brackets <code>[]</code>, so to get the rate for age 110:</p> In\u00a0[17]: Copied! <pre>mort_table[110]\n</pre> mort_table[110] Out[17]: <pre>0.3356707392422082</pre> In\u00a0[18]: Copied! <pre>class Basis:\n    def __init__(self, mort_table, disc_rate_pa):\n        self.mort_table = mort_table\n        self.disc_rate_pa = disc_rate_pa\n        self.disc_rate_pm = (1 + disc_rate_pa) ** (1/12) - 1\n</pre> class Basis:     def __init__(self, mort_table, disc_rate_pa):         self.mort_table = mort_table         self.disc_rate_pa = disc_rate_pa         self.disc_rate_pm = (1 + disc_rate_pa) ** (1/12) - 1 <p>We can create a class instance with our specific values, passing in the mortality table (<code>mort_table</code>) and a flat discount rate of 4% per annum</p> In\u00a0[19]: Copied! <pre>basis3 = Basis(mort_table=mort_table, disc_rate_pa = 0.04)\nbasis3.mort_table[120]\n</pre> basis3 = Basis(mort_table=mort_table, disc_rate_pa = 0.04) basis3.mort_table[120] Out[19]: <pre>0.6356966578357008</pre> <p>Doing a quick check that the monthly discount rate is calculated:</p> In\u00a0[20]: Copied! <pre>basis3.disc_rate_pm\n</pre> basis3.disc_rate_pm Out[20]: <pre>0.0032737397821989145</pre> <p>Updating the model to look up the mortality table, the key change is the addition of <code>q_x</code> which looks up <code>self.basis.mort_table</code>.</p> In\u00a0[21]: Copied! <pre>class Model3(heavylight.Model):\n    def t(self, t):\n        \"\"\"time\"\"\"\n        return t\n    \n    def num_alive(self, t):\n        \"\"\"probability that life is alive at time t, given alive at time 0\"\"\"\n        if t == 0:\n            return 1\n        else:\n            return self.num_alive(t - 1) - self.num_deaths(t - 1)     # deaths moved to a separate method\n        \n    def num_deaths(self, t):\n        \"\"\"number of deaths occuring between time t-1 and t\"\"\"\n        if t &lt; 0:\n            return 0\n        else:\n            return self.num_alive(t) * self.q_x(t)\n\n    def q_x(self, t):\n        return self.basis.mort_table[self.age(t)] / 12   # somewhat crude to get monthly mortality\n\n    def age(self, t):\n        \"\"\"age in years at time t\"\"\"\n        if t == 0:\n            return self.data[\"init_age\"]\n        elif t % 12 == 0:\n            return self.age(t - 1) + 1\n        else:\n            return self.age(t - 1)\n</pre> class Model3(heavylight.Model):     def t(self, t):         \"\"\"time\"\"\"         return t          def num_alive(self, t):         \"\"\"probability that life is alive at time t, given alive at time 0\"\"\"         if t == 0:             return 1         else:             return self.num_alive(t - 1) - self.num_deaths(t - 1)     # deaths moved to a separate method              def num_deaths(self, t):         \"\"\"number of deaths occuring between time t-1 and t\"\"\"         if t &lt; 0:             return 0         else:             return self.num_alive(t) * self.q_x(t)      def q_x(self, t):         return self.basis.mort_table[self.age(t)] / 12   # somewhat crude to get monthly mortality      def age(self, t):         \"\"\"age in years at time t\"\"\"         if t == 0:             return self.data[\"init_age\"]         elif t % 12 == 0:             return self.age(t - 1) + 1         else:             return self.age(t - 1) <p>Running this - picking a longer projection and an older age so we have higher q_x values:</p> In\u00a0[22]: Copied! <pre>data3 = dict(init_age = 65)\n\nmodel3 = Model3(data=data3, basis=basis3, proj_len = 361)\nmodel3.df\n</pre> data3 = dict(init_age = 65)  model3 = Model3(data=data3, basis=basis3, proj_len = 361) model3.df Out[22]: t num_alive num_deaths q_x age 0 0 1.000000 0.001649 0.001649 65 1 1 0.998351 0.001646 0.001649 65 2 2 0.996705 0.001643 0.001649 65 3 3 0.995061 0.001641 0.001649 65 4 4 0.993421 0.001638 0.001649 65 ... ... ... ... ... ... 356 356 0.192231 0.001942 0.010100 94 357 357 0.190289 0.001922 0.010100 94 358 358 0.188367 0.001902 0.010100 94 359 359 0.186465 0.001883 0.010100 94 360 360 0.184581 0.001986 0.010762 95 <p>361 rows \u00d7 5 columns</p> <p>We can plot <code>age</code> against <code>q_x</code> to check it is broadly exponential:</p> In\u00a0[23]: Copied! <pre>model3.df.plot(x='age', y='q_x');\n</pre> model3.df.plot(x='age', y='q_x'); <p>And likewise, have a look at the pattern of deaths - starting around 0.02, and tailing off.  The saw type pattern is because ages are integer, so the same rate is used for 12 valuation periods.</p> In\u00a0[24]: Copied! <pre>model3.df.plot(x='t', y='num_deaths');\n</pre> model3.df.plot(x='t', y='num_deaths'); In\u00a0[25]: Copied! <pre>class Model4(heavylight.Model):\n    basis: Basis  #\u00a0added here to allow code auto-completion\n    data: dict\n\n    def t(self, t):\n        \"\"\"time\"\"\"\n        return t\n    \n    def num_alive(self, t):\n        \"\"\"probability that life is alive at time t, given alive at time 0\"\"\"\n        if t == 0:\n            return 1\n        else:\n            return self.num_alive(t - 1) - self.num_deaths(t - 1)     # deaths moved to a separate method\n        \n    def num_deaths(self, t):\n        \"\"\"number of deaths occuring between time t-1 and t\"\"\"\n        if t &lt; 0:\n            return 0\n        else:\n            return self.num_alive(t) * self.q_x_m(t)\n\n    def q_x(self, t):\n        \"\"\"Annual mortality rate\"\"\"\n        return self.basis.mort_table[self.age(t)]\n    \n    def q_x_m(self, t):\n        \"\"\"Monthly mortality rate\"\"\"\n        return 1 - (1 - self.q_x(t)) ** (1/12)\n\n    def age(self, t):\n        \"\"\"age in years at time t\"\"\"\n        if t == 0:\n            return self.data[\"init_age\"]\n        elif t % 12 == 0:\n            return self.age(t - 1) + 1\n        else:\n            return self.age(t - 1)\n        \n    def expected_claim(self, t):\n        return self.data[\"sum_assured\"] * self.num_deaths(t)\n    \n    def v(self, t):\n        \"\"\"Present value factor for time t, discounting back to time 0\"\"\"\n        if t == 0:\n            return 1.0\n        else:\n            return self.v(t - 1) / (1 + self.basis.disc_rate_pm)\n    \n    def pv_claim(self, t):\n        \"\"\"present value of the expected claim occuring at time t\"\"\"\n        return self.expected_claim(t) * self.v(t)\n    \n</pre> class Model4(heavylight.Model):     basis: Basis  #\u00a0added here to allow code auto-completion     data: dict      def t(self, t):         \"\"\"time\"\"\"         return t          def num_alive(self, t):         \"\"\"probability that life is alive at time t, given alive at time 0\"\"\"         if t == 0:             return 1         else:             return self.num_alive(t - 1) - self.num_deaths(t - 1)     # deaths moved to a separate method              def num_deaths(self, t):         \"\"\"number of deaths occuring between time t-1 and t\"\"\"         if t &lt; 0:             return 0         else:             return self.num_alive(t) * self.q_x_m(t)      def q_x(self, t):         \"\"\"Annual mortality rate\"\"\"         return self.basis.mort_table[self.age(t)]          def q_x_m(self, t):         \"\"\"Monthly mortality rate\"\"\"         return 1 - (1 - self.q_x(t)) ** (1/12)      def age(self, t):         \"\"\"age in years at time t\"\"\"         if t == 0:             return self.data[\"init_age\"]         elif t % 12 == 0:             return self.age(t - 1) + 1         else:             return self.age(t - 1)              def expected_claim(self, t):         return self.data[\"sum_assured\"] * self.num_deaths(t)          def v(self, t):         \"\"\"Present value factor for time t, discounting back to time 0\"\"\"         if t == 0:             return 1.0         else:             return self.v(t - 1) / (1 + self.basis.disc_rate_pm)          def pv_claim(self, t):         \"\"\"present value of the expected claim occuring at time t\"\"\"         return self.expected_claim(t) * self.v(t)      <p>We've added <code>sum_assured</code> in the code as a data item, so we'll update our data dictionary with <code>sum_assured</code>.  The basis is unchanged from the basis object we created earlier, called <code>basis3</code>.</p> In\u00a0[26]: Copied! <pre>data4 = dict(init_age = 65,\n             sum_assured = 100_000,\n             )\n\nmodel4 = Model4(data=data4, basis=basis3, proj_len = 361)\nmodel4.df\n</pre> data4 = dict(init_age = 65,              sum_assured = 100_000,              )  model4 = Model4(data=data4, basis=basis3, proj_len = 361) model4.df Out[26]: t num_alive num_deaths q_x q_x_m age expected_claim v pv_claim 0 0 1.000000 0.001664 0.019787 0.001664 65 166.403394 1.000000 166.403394 1 1 0.998336 0.001661 0.019787 0.001664 65 166.126493 0.996737 165.584413 2 2 0.996675 0.001659 0.019787 0.001664 65 165.850053 0.993485 164.769462 3 3 0.995016 0.001656 0.019787 0.001664 65 165.574073 0.990243 163.958523 4 4 0.993360 0.001653 0.019787 0.001664 65 165.298552 0.987012 163.151574 ... ... ... ... ... ... ... ... ... ... 356 356 0.181641 0.001945 0.121199 0.010709 94 194.513192 0.312376 60.761245 357 357 0.179696 0.001924 0.121199 0.010709 94 192.430222 0.311357 59.914431 358 358 0.177772 0.001904 0.121199 0.010709 94 190.369557 0.310341 59.079418 359 359 0.175868 0.001883 0.121199 0.010709 94 188.330959 0.309328 58.256043 360 360 0.173985 0.001993 0.129143 0.011457 95 199.334525 0.308319 61.458555 <p>361 rows \u00d7 9 columns</p> <p>We can now calculate the present value of claims, using the .sum() method:</p> In\u00a0[27]: Copied! <pre>model4.pv_claim.sum()\n</pre> model4.pv_claim.sum() Out[27]: <pre>47228.33160491008</pre> <p>Finally - let's run the model a few times in a loop to see the sensitivity of claims to age:</p> In\u00a0[28]: Copied! <pre>for age in [35, 45, 55, 65]:\n    proj_result = Model4(data=dict(init_age=age, sum_assured=100_000),basis=basis3, proj_len=361)\n    pv_claim = proj_result.pv_claim.sum()\n    print(f\"Age: {age} \u2192 PV Claim: {pv_claim:0,.2f}\")\n</pre> for age in [35, 45, 55, 65]:     proj_result = Model4(data=dict(init_age=age, sum_assured=100_000),basis=basis3, proj_len=361)     pv_claim = proj_result.pv_claim.sum()     print(f\"Age: {age} \u2192 PV Claim: {pv_claim:0,.2f}\") <pre>Age: 35 \u2192 PV Claim: 12,358.30\nAge: 45 \u2192 PV Claim: 20,323.02\nAge: 55 \u2192 PV Claim: 32,279.74\nAge: 65 \u2192 PV Claim: 47,228.33\n</pre> <p>From here the model result can be used downstream in other code, or exported to an file, e.g. using the pandas method <code>to_excel</code> or <code>to_csv</code>. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html</p>"},{"location":"getting_started/intro_to_heavylight/#an-introduction-to-actuarial-modelling-with-heavylight","title":"An Introduction to Actuarial Modelling With Heavylight\u00b6","text":"<p>This page provides a guided walkthrough of how to develop and run an actuarial model using <code>heavylight</code>.</p>"},{"location":"getting_started/intro_to_heavylight/#before-you-start","title":"Before you start\u00b6","text":"<ul> <li>Ensure you have Python 3.8 or newer installed: Download Python</li> <li>Install heavylight from pypi: <code>python -m pip install heavylight</code> or <code>pip install heavylight</code></li> <li>If working interactively, install jupyter lab</li> </ul> <p>Once installed, check libraries are installed, and check the version of heavylight:</p>"},{"location":"getting_started/intro_to_heavylight/#overview","title":"Overview\u00b6","text":"<p>This document covers the following stages in development and execution of the model:</p> <ul> <li>define the model</li> <li>pass in data (or simulate)</li> <li>pass in assumptions</li> <li>run the model</li> <li>viewing the results</li> </ul> <p>In practice, defining, loading data and loading assumptions need to be carried out in parallel, so we will define several iterations of the model (<code>Model1</code>, <code>Model2</code>...), introducing one concept at a time.  You can skip to the end to see the final iteration of the model.</p> <p>This guide is designed to give an introduction, so doesn't cover some of the more advanced techniques around performance optimisation (vectorisation using numpy/tensors) or table/model design.</p>"},{"location":"getting_started/intro_to_heavylight/#define-the-model","title":"Define the model\u00b6","text":"<p>The model is defined as a subclass of <code>heavylight.Model</code>, and each value or variable we want to calculate is defined as a method (a function belonging to the class).</p> <p>In actuarial models we are usually interested in projecting through time, this corresponds to methods with one argument <code>t</code>.  When the model is run these are automatically calculated, for each time period specified up to <code>proj_len</code>.</p> <p><code>self</code> is always the first parameter in a python class method.  This allows us to refer to the class instance, including any other data attributes or methods, without passing them into the method separately.</p> <p>Want to know more about classes?  The python class tutorial can help: https://docs.python.org/3/tutorial/classes.html</p>"},{"location":"getting_started/intro_to_heavylight/#exploring-the-results-and-calculating-more-values","title":"Exploring the results, and calculating more values\u00b6","text":"<p>We can see that num alive runs off as expected, 1, 0.99, 0.99^2, 0.99^3...</p> <p>We can view the values for a variable using <code>.values</code>:</p>"},{"location":"getting_started/intro_to_heavylight/#passing-data-to-the-model","title":"Passing data to the model\u00b6","text":"<p>Our model isn't going to be that useful unless we can pass in data, for this model we are interested in the probability of being alive at each valuation point, the probability of dying then, and the expected claim cost arising.  (Sum Assured x Number of Deaths)</p> <p>We'll add in two new methods, <code>num_deaths</code> to count the expected deaths occuring, and <code>age</code> to calculate the current age.</p> <p><code>num_deaths</code> is dependent on the number alive at the start of the period, and the mortality rate <code>q_x</code>: as we've not defined a mortality table we'll fudge this for now as being a linear function of age $q_x(t) = 0.001 (x + t)$</p> <p>For the <code>age</code> variable, we want to get this from data at <code>t = 0</code> from the field <code>init_age</code>.  There are lots of different ways to store and pass in data, for example in a dictionary, using a dataclass, or as individual variables.  For this example we'll use a dictionary, which will be stored in the model as <code>data</code>.  We can then query the data field using <code>self.data[\"init_age]</code>.</p>"},{"location":"getting_started/intro_to_heavylight/#adding-a-table-to-store-structured-assumptions","title":"Adding a table to store structured assumptions\u00b6","text":"<p>Heavylight comes with the <code>Table</code> class which is optional, and provides a high performance table capable of handling most actuarial tables, and loading in data from pandas dataframes, Excel, and CSV formats.  See the main Tables documentation for the latest details.</p> <p>Here we will create a mortality table, rather than loading it it, although in practice most tables will be pre-computed.</p> <p>We start by creating a dataframe, with ages running from 16 to 130.  The <code>Table</code> class needs to know what type the key is, in this case we are using integers, and we want to ensure that the lookup doesn't go past the lower and upper values (so any values under 16 or over 130 will look up 16 or 130 respectively), so we are specifing type <code>int_bound</code>.   The overall key is therefore <code>age|int_bound</code>.</p>"},{"location":"getting_started/intro_to_heavylight/#incorporating-the-mortality-table-into-the-model","title":"Incorporating the mortality table into the model\u00b6","text":"<p>We could now create a basis dictionary (much like the data dictionary), however for this case we'll use a small class for the basis.  This will give us the option to use <code>.item</code> notation rather than dictionary item lookups <code>['item']</code>.  Either approach works.</p> <p>At the same time as adding the mortality table, let's at a flat discount rate, and precompute the monthly equivalent rate.  Note that power in python is accomplished with the <code>**</code> operator, e.g. if we wrote <code>=2^3</code> in Excel, the python equivalent would be <code>2**3</code>.</p> <p>Python operators are listed here: https://docs.python.org/3/library/operator.html#mapping-operators-to-functions</p>"},{"location":"getting_started/intro_to_heavylight/#adding-cashflows-expected-claim-premium-and-present-values","title":"Adding Cashflows - expected claim, premium and present values\u00b6","text":"<p>The q_x/12 approximation is a little poor, so this version replaces it with an appropriately 12thly-compounding version.</p> <p>There are a few different ways we can work out present values, we could either pull out cashflows from the model and use a separate <code>npv()</code> function, create a discounting model, however for simplicity in this case we'll add a <code>v</code> function.  In line with general actuarial practice which uses $v^t$: https://en.wikipedia.org/wiki/Actuarial_present_value</p> <p><code>pv_claim</code> is an intermediate function, if we take the sum of this, it is the equivalent of Excel <code>SUMPRODUCT</code> on the <code>v</code> column and the <code>expected_claim</code> column.</p>"},{"location":"getting_started/intro_to_heavylight/#what-next","title":"What next?\u00b6","text":"<p>That completes this introduction, you could try adding some variables of your own to the model, for example:</p> <ul> <li>Adding an <code>expected_premium</code> function, which takes <code>monthly_premium</code> from data.</li> <li>Adding a maximum policy term (at the moment it is controlled by <code>proj_len</code>).</li> <li>Use a yield curve rather than a flat rate</li> </ul>"},{"location":"theory/memory_optimization/","title":"What is memory optimization?","text":""},{"location":"theory/memory_optimization/#a-simple-example","title":"A simple example","text":"<p>Actuarial models involve projecting financial quantities across timesteps. It is common for the value at a timestep to depend on values from the previous timestep. For a simple example</p> <ul> <li><code>f(t)</code> is used by <code>g(t)</code></li> <li><code>g(t)</code> is used by <code>g(t+1)</code>, <code>f(t+1)</code>, and <code>h(t)</code></li> <li><code>h(t)</code> is not used by any other functions</li> </ul>"},{"location":"theory/memory_optimization/#why-clear-the-cache","title":"Why clear the cache","text":"<p>The dependency structure of actuarial models requires caching to run recursive function calls efficiently. Suppose we have <code>F</code> functions each run for <code>T</code> timesteps, and each function returns an array of size <code>P</code>. At the end of the calculation the memory consumption of the caches will be <code>F * T * P</code>.</p> <p>In practice, it is common for a timestep to be a month. Projecting results 20 years into the future means that <code>T = 240</code>. But because we know that functions only depend on the previous timestep, we know that after calculating results for <code>T = 2</code> that we can clear all caches where <code>T == 1</code>, they are no longer needed.</p> <p>Clearing the cache in this manner, the number of cached values would no longer depend on the number of timesteps, and we reduce the cache size to less than 1% of its original size.</p> <p>How many policies?</p> <p>16 GB can store 2 billion 64 bit numbers. Consider a model with 10 formulas, 240 timesteps. <code>F * T * P</code> = <code>10 * 240 * P</code> = 2 billion and <code>P = 833,333</code> which is pretty good. Optimizing away the dependency on timesteps, <code>F * P</code> =  <code>10 * P</code> = 2 billion and P = 200,000,000.</p> <p>Model bigger than RAM</p> <p>On the CPU if we try to use more memory than is available, it can result in severe performance degredations due to \"swapping memory on disk\", and ultimately our program can crash. On the GPU, you will simply get an error <code>RuntimeError: CUDA out of memory.</code></p> <p>If your model is using too much memory even after optimization, you will have to process results in batches, or use a compute cluster and run models in parallel.</p>"},{"location":"theory/memory_optimization/#implementation-details","title":"Implementation details","text":"<p>We collect the dependency graph of the functions, this is done by running the model with a small sample of the data, <code>P = 1</code> for example. We call this the warm-up run.</p> <p> </p> <p>Internally, we track the last function to use a cached value. For an execution order of <code>[\"f(0)\", \"g(0)\", \"h(0)\", \"f(1)\", \"g(1)\", \"h(1)\", ... ]</code> the arrow between <code>g(0)</code> and <code>g(1)</code> in the diagram below represents that <code>g(1)</code> is the last function to require the cached value of <code>g(0)</code>.</p> <p> </p> <p>Since <code>g(1)</code> is the last function to require the cached value of <code>g(0)</code> we make a new data structure, the arrow between <code>g(1)</code> and <code>g(0)</code> below now represents that <code>g(1)</code> clears the cache of <code>g(0)</code>. Also, functions with no dependencies can clear their cache after being calculated.</p> <p> </p> <p>Dynamic dependency graphs</p> <p>Function dependencies that are dynamic depending on values at runtime cannot be memory optimized. The results will still be correct, the memory consumption may increase with the timesteps though. This is generally not the case in vectorized models where conditional logic does not impact control flow due to use of functions like <code>np.where</code>.</p> <pre><code>if np.sum(net_cf(t)) &lt; 0:\n    return g(t)\nelse:.\n    return h(t)\n</code></pre> <p>A simpler algorithm</p> <p>If you are certain that your model always only depends on the previous timestep, there are alternative implementations that do not involve a warm-up run but simply clear the cache at <code>f(t-2)</code> after calculating a value at <code>f(t)</code>. In that case, the cache will generally be of size <code>2 * F * P</code>. This simpler algorithm will also be able to optimize through dynamic dependency graphs.</p> <p>The more complex algorithm will produce a smaller max cache size, and works in a more general setting.</p>"},{"location":"theory/recursive_life_insurance/","title":"Basic recursive life insurance models","text":"In\u00a0[1]: Copied! <pre>mortality_rate = .01\ndeath_probabilities = {}\nalive_probabilities = {0: 1.0}\nfor t in range(3):\n    probability_death = alive_probabilities[t] * mortality_rate\n    death_probabilities[t] = probability_death\n    alive_probabilities[t + 1] = alive_probabilities[t] - probability_death\n\nprint(alive_probabilities)\n</pre> mortality_rate = .01 death_probabilities = {} alive_probabilities = {0: 1.0} for t in range(3):     probability_death = alive_probabilities[t] * mortality_rate     death_probabilities[t] = probability_death     alive_probabilities[t + 1] = alive_probabilities[t] - probability_death  print(alive_probabilities) <pre>{0: 1.0, 1: 0.99, 2: 0.9801, 3: 0.970299}\n</pre> <p>This code works, but we want something that is easier to reason about. People generally prefer expressing formulas in a recursive style as below.</p> In\u00a0[2]: Copied! <pre>def deaths(t):\n    \"\"\"probability of dying in [t, t+1)\"\"\"\n    return alive(t) * mortality_rate\n\ndef alive(t):\n    \"\"\"probability of being alive at time t\"\"\"\n    if t &lt;= 0:\n        return 1\n    return alive(t-1) - deaths(t-1)\n\nprint(f\"recursive {alive(2)=}\")\nprint(f\"iterative {alive_probabilities[2]=}\")\nprint(\"Same result, nice\")\n</pre> def deaths(t):     \"\"\"probability of dying in [t, t+1)\"\"\"     return alive(t) * mortality_rate  def alive(t):     \"\"\"probability of being alive at time t\"\"\"     if t &lt;= 0:         return 1     return alive(t-1) - deaths(t-1)  print(f\"recursive {alive(2)=}\") print(f\"iterative {alive_probabilities[2]=}\") print(\"Same result, nice\") <pre>recursive alive(2)=0.9801\niterative alive_probabilities[2]=0.9801\nSame result, nice\n</pre> In\u00a0[3]: Copied! <pre>def dead(t):\n    print(f\"dead({t})\")\n    return alive(t) * mortality_rate\n\ndef alive(t):\n    print(f\"alive({t})\")\n    if t &lt;= 0:\n        return 1\n    return alive(t-1) - dead(t-1)\n\nalive(2)\n</pre> def dead(t):     print(f\"dead({t})\")     return alive(t) * mortality_rate  def alive(t):     print(f\"alive({t})\")     if t &lt;= 0:         return 1     return alive(t-1) - dead(t-1)  alive(2) <pre>alive(2)\nalive(1)\nalive(0)\ndead(0)\nalive(0)\ndead(1)\nalive(1)\nalive(0)\ndead(0)\nalive(0)\n</pre> Out[3]: <pre>0.9801</pre> <p>From the logs above, we can imagine that the function calls to calculate <code>alive(2)</code> are structured in the following way.</p> <pre><code>               alive(2)\n            _______|__________\n           /                  \\\n        alive(1)             dead(1)\n       /        \\              |\nalive(0)       dead(0)       alive(1)\n                 |          /        \\\n              alive(0)   alive(0)   dead(0)\n                                       |\n                                    alive(0)\n</code></pre> <p>The number of function calls grows exponentially. <code>alive(t)</code> will call <code>alive(t-1)</code> at least twice, causing <code>alive(t-2)</code> to be called at least 4 times, and so on until our base case <code>alive(0)</code> is hit. Let's do another experiment to verify the exponential growth.</p> In\u00a0[4]: Copied! <pre>def experiment_problematic_recursion(t):\n    def dead(t):\n        \"\"\"probability of dying in [t, t+1)\"\"\"\n        return alive(t) * mortality_rate\n    total = 0\n    def alive(t):\n        \"\"\"probability of being alive at time t\"\"\"\n        nonlocal total\n        total += 1\n        if t &lt;= 0:\n            return 1\n        return alive(t-1) - dead(t-1)\n    alive(t)\n    return total\n\ndef run_experiment_problematic_recursion():\n    print(\"Running experiment_no_cache\")\n    for t in range(5):\n        print(f\"alive({t}) makes {experiment_problematic_recursion(t)} calls to alive\")\n\nrun_experiment_problematic_recursion()\n</pre> def experiment_problematic_recursion(t):     def dead(t):         \"\"\"probability of dying in [t, t+1)\"\"\"         return alive(t) * mortality_rate     total = 0     def alive(t):         \"\"\"probability of being alive at time t\"\"\"         nonlocal total         total += 1         if t &lt;= 0:             return 1         return alive(t-1) - dead(t-1)     alive(t)     return total  def run_experiment_problematic_recursion():     print(\"Running experiment_no_cache\")     for t in range(5):         print(f\"alive({t}) makes {experiment_problematic_recursion(t)} calls to alive\")  run_experiment_problematic_recursion() <pre>Running experiment_no_cache\nalive(0) makes 1 calls to alive\nalive(1) makes 3 calls to alive\nalive(2) makes 7 calls to alive\nalive(3) makes 15 calls to alive\nalive(4) makes 31 calls to alive\n</pre> <p>The formula appears to be <code>pow(2, t+1) - 1</code>.</p> In\u00a0[5]: Copied! <pre>dead_cache = {}\ndef dead(t):\n    if t in dead_cache:\n        return dead_cache[t]\n    print(f\"dead({t})\")\n    dead_cache[t] = alive(t) * mortality_rate\n    return dead_cache[t]\n\nalive_cache={}\ndef alive(t):\n    if t in alive_cache:\n        return alive_cache[t]\n    print(f\"alive({t})\")\n    if t &lt;= 0:\n        alive_cache[t] = 1\n    else:\n        alive_cache[t] = alive(t-1) - dead(t-1)\n    return alive_cache[t]\n\nalive(2)\n</pre> dead_cache = {} def dead(t):     if t in dead_cache:         return dead_cache[t]     print(f\"dead({t})\")     dead_cache[t] = alive(t) * mortality_rate     return dead_cache[t]  alive_cache={} def alive(t):     if t in alive_cache:         return alive_cache[t]     print(f\"alive({t})\")     if t &lt;= 0:         alive_cache[t] = 1     else:         alive_cache[t] = alive(t-1) - dead(t-1)     return alive_cache[t]  alive(2) <pre>alive(2)\nalive(1)\nalive(0)\ndead(0)\ndead(1)\n</pre> Out[5]: <pre>0.9801</pre> <p>The functions that are executed and not looked up from the cache are called cache misses. We make the graph of the cache misses -</p> <pre><code>                   alive(2)\n                ______|______\n               /             \\\n           alive(1)         dead(1)\n           /     \\           \n    alive(0)     dead(0)   \n</code></pre> <p>Our tree from earlier with no cache -</p> <pre><code>               alive(2)\n            _______|__________\n           /                  \\\n        alive(1)             dead(1)\n       /        \\              |\nalive(0)       dead(0)       alive(1)\n                 |          /        \\\n              alive(0)   alive(0)   dead(0)\n                                       |\n                                    alive(0)\n</code></pre> <p>The difference is that we never execute a function twice when we use the cache.</p> <p>The difference becomes more important as <code>t</code> becomes large.</p> In\u00a0[6]: Copied! <pre>def experiment_cache(t):\n    cache_misses_alive = 0\n    alive_cache={}\n    def alive(t):\n        nonlocal cache_misses_alive\n        if t in alive_cache:\n            return alive_cache[t]\n        cache_misses_alive += 1\n        if t &lt;= 0:\n            alive_cache[t] = 1\n        else:\n            alive_cache[t] = alive(t-1) - dead(t-1)\n        return alive_cache[t]\n    dead_cache = {}\n    def dead(t):\n        if t in dead_cache:\n            return dead_cache[t]\n        dead_cache[t] = alive(t) * mortality_rate\n        return dead_cache[t]\n    alive(t)\n    return cache_misses_alive\n\ndef run_experiment_cache():\n    print(\"Running experiment_cache\")\n    for t in range(5):\n        print(f\"alive({t}) makes {experiment_cache(t)} calls to alive\")\n\nrun_experiment_cache()\nprint(\"\\ncompared to\\n\")\nrun_experiment_problematic_recursion()\n</pre> def experiment_cache(t):     cache_misses_alive = 0     alive_cache={}     def alive(t):         nonlocal cache_misses_alive         if t in alive_cache:             return alive_cache[t]         cache_misses_alive += 1         if t &lt;= 0:             alive_cache[t] = 1         else:             alive_cache[t] = alive(t-1) - dead(t-1)         return alive_cache[t]     dead_cache = {}     def dead(t):         if t in dead_cache:             return dead_cache[t]         dead_cache[t] = alive(t) * mortality_rate         return dead_cache[t]     alive(t)     return cache_misses_alive  def run_experiment_cache():     print(\"Running experiment_cache\")     for t in range(5):         print(f\"alive({t}) makes {experiment_cache(t)} calls to alive\")  run_experiment_cache() print(\"\\ncompared to\\n\") run_experiment_problematic_recursion() <pre>Running experiment_cache\nalive(0) makes 1 calls to alive\nalive(1) makes 2 calls to alive\nalive(2) makes 3 calls to alive\nalive(3) makes 4 calls to alive\nalive(4) makes 5 calls to alive\n\ncompared to\n\nRunning experiment_no_cache\nalive(0) makes 1 calls to alive\nalive(1) makes 3 calls to alive\nalive(2) makes 7 calls to alive\nalive(3) makes 15 calls to alive\nalive(4) makes 31 calls to alive\n</pre> <p>We no longer have an exponential number of function calls being made.</p>"},{"location":"theory/recursive_life_insurance/#basic-recursive-life-insurance-models","title":"Basic recursive life insurance models\u00b6","text":"<p>Suppose that if a person is alive at the beginning of a year, they have a 1% chance of dying by the end of the year. Actuaries say they have a constant mortality rate of <code>.01</code>.</p>"},{"location":"theory/recursive_life_insurance/#an-iterative-life-insurance-model","title":"An iterative life insurance model\u00b6","text":""},{"location":"theory/recursive_life_insurance/#a-recursive-life-insurance-model","title":"A recursive life insurance model\u00b6","text":""},{"location":"theory/recursive_life_insurance/#the-problem-with-recursion","title":"The problem with recursion\u00b6","text":"<p>Let's add some print statements and see if we can trace what the code is doing.</p>"},{"location":"theory/recursive_life_insurance/#fixing-the-problem-with-recursion","title":"Fixing the problem with recursion\u00b6","text":"<p>If we have calculated <code>alive(5)</code> once, we store the result and just return that the next time <code>alive(5)</code> needs to be calculated. This avoids making an exponential number of recursive calls.</p> <p>This is called recursion with memoization. When we store the result of a function, we say that it has been cached and it is stored in the cache.</p>"},{"location":"theory/recursive_life_insurance/#discussion","title":"Discussion\u00b6","text":"<p>The root cause of our performance problems with recursion was that <code>alive(t)</code> calls <code>alive(t-1)</code> twice, which results in <code>alive(t-2)</code> being called four times, and so on.</p> <p>This problem is not specific to actuarial science. Consider the following code that calculates Fibonacci numbers recursively.</p> <pre>def fib(n):\n    if n &lt;= 1:\n        return n\n    return fib(n-1) + fib(n-2)\n</pre> <p>Recursion with memoization is a common strategy for solving coding interview questions:</p> <ul> <li>Easy: https://leetcode.com/problems/climbing-stairs/description/</li> <li>Easy: https://leetcode.com/problems/min-cost-climbing-stairs/description/</li> <li>Medium: https://leetcode.com/problems/knight-probability-in-chessboard/description/</li> <li>Hard: https://leetcode.com/problems/sum-of-distances-in-tree/description/</li> <li>Hard: https://leetcode.com/problems/handshakes-that-dont-cross/description/</li> </ul>"},{"location":"theory/vectorized_models/","title":"Introduction to vectorized models","text":"In\u00a0[108]: Copied! <pre>from heavylight import LightModel\nimport pandas as pd\nfrom collections import defaultdict\nimport numpy as np\n\n\nclass EasyModel(LightModel):\n    def __init__(self, mortality_rate):\n        super().__init__()\n        self.mortality_rate = mortality_rate\n\n    def pols_if(self, t):\n        if t == 0:\n            return 1\n        return self.pols_if(t-1) - self.pols_death(t-1)\n    \n    def pols_death(self, t):\n        return self.mortality_rate * self.pols_if(t)\n    \n    \nsingle = EasyModel(0.01)\nsingle.RunModel(100)\nsingle.df\n</pre> from heavylight import LightModel import pandas as pd from collections import defaultdict import numpy as np   class EasyModel(LightModel):     def __init__(self, mortality_rate):         super().__init__()         self.mortality_rate = mortality_rate      def pols_if(self, t):         if t == 0:             return 1         return self.pols_if(t-1) - self.pols_death(t-1)          def pols_death(self, t):         return self.mortality_rate * self.pols_if(t)           single = EasyModel(0.01) single.RunModel(100) single.df Out[108]: pols_death pols_if 0 0.010000 1.000000 1 0.009900 0.990000 2 0.009801 0.980100 3 0.009703 0.970299 4 0.009606 0.960596 ... ... ... 96 0.003810 0.381047 97 0.003772 0.377237 98 0.003735 0.373464 99 0.003697 0.369730 100 0.003660 0.366032 <p>101 rows \u00d7 2 columns</p> In\u00a0[109]: Copied! <pre>def get_rates_results_no_vectorization(rate_count: int, projection_length: int):\n    all_models = []\n    for i in range(rate_count):\n        mortality_rate = i / rate_count\n        model_with_rate = EasyModel(mortality_rate)\n        model_with_rate.RunModel(projection_length)\n        all_models.append(model_with_rate)\n    combined_cache = defaultdict(lambda: defaultdict(list))\n    for model in all_models:\n        for function_key, function_results in model.cache.items():\n            for result_key, result_value in function_results.items():\n                combined_cache[function_key][result_key].append(result_value)\n    combined_df = pd.DataFrame(combined_cache)\n    return combined_df\n\nget_rates_results_no_vectorization(rate_count=1000, projection_length=100)\n</pre> def get_rates_results_no_vectorization(rate_count: int, projection_length: int):     all_models = []     for i in range(rate_count):         mortality_rate = i / rate_count         model_with_rate = EasyModel(mortality_rate)         model_with_rate.RunModel(projection_length)         all_models.append(model_with_rate)     combined_cache = defaultdict(lambda: defaultdict(list))     for model in all_models:         for function_key, function_results in model.cache.items():             for result_key, result_value in function_results.items():                 combined_cache[function_key][result_key].append(result_value)     combined_df = pd.DataFrame(combined_cache)     return combined_df  get_rates_results_no_vectorization(rate_count=1000, projection_length=100) Out[109]: pols_if pols_death 0 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... [0.0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006... 1 [1.0, 0.999, 0.998, 0.997, 0.996, 0.995, 0.994... [0.0, 0.000999, 0.001996, 0.002991, 0.003984, ... 2 [1.0, 0.998001, 0.996004, 0.994009, 0.992016, ... [0.0, 0.000998001, 0.001992008, 0.002982027, 0... 3 [1.0, 0.997002999, 0.994011992, 0.991026973, 0... [0.0, 0.000997002999, 0.001988023984, 0.002973... 4 [1.0, 0.996005996001, 0.992023968016, 0.988053... [0.0, 0.000996005996001, 0.0019840479360320002... ... ... ... 96 [1.0, 0.9084203817511969, 0.8251482132286804, ... [0.0, 0.0009084203817511969, 0.001650296426457... 97 [1.0, 0.9075119613694457, 0.8234979168022231, ... [0.0, 0.0009075119613694457, 0.001646995833604... 98 [1.0, 0.9066044494080763, 0.8218509209686187, ... [0.0, 0.0009066044494080763, 0.001643701841937... 99 [1.0, 0.9056978449586682, 0.8202072191266815, ... [0.0, 0.0009056978449586683, 0.001640414438253... 100 [1.0, 0.9047921471137096, 0.8185668046884281, ... [0.0, 0.0009047921471137096, 0.001637133609376... <p>101 rows \u00d7 2 columns</p> In\u00a0[110]: Copied! <pre>vectorized_model = EasyModel(np.linspace(0, .999, 1000))\nvectorized_model.RunModel(100)\nvectorized_model.df\n</pre> vectorized_model = EasyModel(np.linspace(0, .999, 1000)) vectorized_model.RunModel(100) vectorized_model.df Out[110]: pols_death pols_if 0 [0.0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006... 1 1 [0.0, 0.000999, 0.001996, 0.002991, 0.003984, ... [1.0, 0.999, 0.998, 0.997, 0.996, 0.995, 0.994... 2 [0.0, 0.000998001, 0.001992008, 0.002982027, 0... [1.0, 0.998001, 0.996004, 0.994009, 0.992016, ... 3 [0.0, 0.000997002999, 0.001988023984, 0.002973... [1.0, 0.997002999, 0.994011992, 0.991026973, 0... 4 [0.0, 0.000996005996001, 0.0019840479360320002... [1.0, 0.996005996001, 0.992023968016, 0.988053... ... ... ... 96 [0.0, 0.0009084203817511969, 0.001650296426457... [1.0, 0.9084203817511969, 0.8251482132286804, ... 97 [0.0, 0.0009075119613694457, 0.001646995833604... [1.0, 0.9075119613694457, 0.8234979168022231, ... 98 [0.0, 0.0009066044494080763, 0.001643701841937... [1.0, 0.9066044494080763, 0.8218509209686187, ... 99 [0.0, 0.0009056978449586683, 0.001640414438253... [1.0, 0.9056978449586682, 0.8202072191266815, ... 100 [0.0, 0.0009047921471137096, 0.001637133609376... [1.0, 0.9047921471137096, 0.8185668046884281, ... <p>101 rows \u00d7 2 columns</p> In\u00a0[111]: Copied! <pre>%%timeit\nget_rates_results_no_vectorization(rate_count=1000, projection_length=100)\n</pre> %%timeit get_rates_results_no_vectorization(rate_count=1000, projection_length=100) <pre>1.45 s \u00b1 63.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre> In\u00a0[112]: Copied! <pre>%%timeit\nvectorized_model.RunModel(proj_len=100)\n</pre> %%timeit vectorized_model.RunModel(proj_len=100) <pre>2.09 ms \u00b1 146 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</pre> In\u00a0[113]: Copied! <pre>vectorized_model.df_agg[:2]\n</pre> vectorized_model.df_agg[:2] Out[113]: pols_death pols_if 0 499.5000 1.0 1 166.6665 500.5 <p>We can fix the bug by initializing <code>pols_if</code> as an array with the correct shape.</p> <pre>    def pols_if(self, t):\n        if t == 0:\n            return np.ones_like(self.mortality_rate)\n        return self.pols_if(t-1) - self.pols_death(t-1)\n</pre> In\u00a0[114]: Copied! <pre>class GoodInitializationModel(LightModel):\n    def __init__(self, mortality_rate):\n        super().__init__()\n        self.mortality_rate = mortality_rate\n\n    def pols_if(self, t):\n        if t == 0:\n            return np.ones_like(self.mortality_rate)\n        return self.pols_if(t-1) - self.pols_death(t-1)\n    \n    def pols_death(self, t):\n        return self.mortality_rate * self.pols_if(t)\n    \nbugfix_model = GoodInitializationModel(np.linspace(0, .999, 1000))\nbugfix_model.RunModel(100)\nbugfix_model.df_agg[:2]\n</pre> class GoodInitializationModel(LightModel):     def __init__(self, mortality_rate):         super().__init__()         self.mortality_rate = mortality_rate      def pols_if(self, t):         if t == 0:             return np.ones_like(self.mortality_rate)         return self.pols_if(t-1) - self.pols_death(t-1)          def pols_death(self, t):         return self.mortality_rate * self.pols_if(t)      bugfix_model = GoodInitializationModel(np.linspace(0, .999, 1000)) bugfix_model.RunModel(100) bugfix_model.df_agg[:2] Out[114]: pols_death pols_if 0 499.5000 1000.0 1 166.6665 500.5 In\u00a0[115]: Copied! <pre>class BroadcastedModel(LightModel):\n    def __init__(self, mortality_rate: np.ndarray, factors: np.ndarray):\n        super().__init__()\n        self.mortality_rate = mortality_rate\n        self.factors = factors\n\n    def pols_if(self, t):\n        if t == 0:\n            return np.ones((len(self.mortality_rate), len(self.factors)))\n        return self.pols_if(t-1) - self.pols_death(t-1)\n    \n    def pols_death(self, t):\n        return self.mortality_rate * (1 + self.factors) * self.pols_if(t)\n</pre> class BroadcastedModel(LightModel):     def __init__(self, mortality_rate: np.ndarray, factors: np.ndarray):         super().__init__()         self.mortality_rate = mortality_rate         self.factors = factors      def pols_if(self, t):         if t == 0:             return np.ones((len(self.mortality_rate), len(self.factors)))         return self.pols_if(t-1) - self.pols_death(t-1)          def pols_death(self, t):         return self.mortality_rate * (1 + self.factors) * self.pols_if(t) In\u00a0[116]: Copied! <pre>broadcasted_model = BroadcastedModel(\n    np.array([.01, .02, .03]), # shape (3,)\n    np.array([[-.01], [0.], [.01]]) # shape (3, 1)\n)\nbroadcasted_model.RunModel(100)\nbroadcasted_model.df\n</pre> broadcasted_model = BroadcastedModel(     np.array([.01, .02, .03]), # shape (3,)     np.array([[-.01], [0.], [.01]]) # shape (3, 1) ) broadcasted_model.RunModel(100) broadcasted_model.df Out[116]: pols_death pols_if 0 [[0.0099, 0.0198, 0.029699999999999997], [0.01... [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, ... 1 [[0.00980199, 0.019407960000000002, 0.02881791... [[0.9901, 0.9802, 0.9703], [0.99, 0.98, 0.97],... 2 [[0.009704950299, 0.019023682392000002, 0.0279... [[0.9802980099999999, 0.96079204, 0.94148209],... 3 [[0.0096088712910399, 0.0186470134806384, 0.02... [[0.970593059701, 0.9417683576079999, 0.913520... 4 [[0.009513743465258606, 0.01827780261372176, 0... [[0.96098418840996, 0.9231213441273616, 0.8863... ... ... ... 96 [[0.003809123061986519, 0.002903195053362312, ... [[0.3847599052511635, 0.14662601279607634, 0.0... 97 [[0.0037714127436728525, 0.002845711791305738,... [[0.380950782189177, 0.14372281774271403, 0.05... 98 [[0.0037340757575104913, 0.0027893666978378844... [[0.3771793694455041, 0.1408771059514083, 0.05... 99 [[0.003697108407511137, 0.0027341372372206942,... [[0.3734452936879936, 0.1380877392535704, 0.05... 100 [[0.0036605070342767766, 0.0026800013199237247... [[0.3697481852804825, 0.13535360201634972, 0.0... <p>101 rows \u00d7 2 columns</p>"},{"location":"theory/vectorized_models/#introduction-to-vectorized-models","title":"Introduction to vectorized models\u00b6","text":"<p>Vectorized models allow us to easily and quickly perform runs with many policies at the same time.</p>"},{"location":"theory/vectorized_models/#example-without-vectorization","title":"Example without vectorization\u00b6","text":"<p>Here we run a model for a single policy</p>"},{"location":"theory/vectorized_models/#many-mortality-rates-no-vectorization","title":"Many mortality rates, no vectorization\u00b6","text":"<p>Suppose we want to run the model for <code>rate_count</code> equally spaces mortality rates between 0 and 1. Without vectorization we need to write some logic to</p> <ul> <li>Run the model for the different rates</li> <li>Collect the results from the different model runs</li> </ul> <p>This is shown below</p>"},{"location":"theory/vectorized_models/#vectorization","title":"Vectorization\u00b6","text":""},{"location":"theory/vectorized_models/#what-is-vectorization","title":"What is vectorization?\u00b6","text":"<p>Vectorization just means using an array library like NumPy so that operations generally happen between arrays and not between single numbers.</p> <p>For example, in the expression</p> <pre>self.pols_if(t-1) - self.pols_death(t-1)\n</pre> <p>The subtraction happens between numpy arrays returned by <code>self.pols_if(t-1)</code> and <code>self.pols_death(t-1)</code>.</p>"},{"location":"theory/vectorized_models/#returning-to-our-example","title":"Returning to our example\u00b6","text":"<p>See that we no longer need to write logic to iterate over the policies.</p>"},{"location":"theory/vectorized_models/#performance-benefits","title":"Performance benefits\u00b6","text":"<p>See that the vectorized code runs much faster</p>"},{"location":"theory/vectorized_models/#why-vectorized-code-is-faster","title":"Why vectorized code is faster\u00b6","text":""},{"location":"theory/vectorized_models/#function-call-overhead","title":"Function call overhead\u00b6","text":"<p>If we have a million policies, each function called will have to be called a million times. There might be 1000 unique function calls in the calculation, so that is a billion function calls. It isn't performant to make a billion function calls due to function call overheads. On top of Python's typical function call overhead, actuarial modeling frameworks will perform additional actions on each function call like checking for cached values.</p> <p>We can avoid making large numbers of function calls with vectorization.</p>"},{"location":"theory/vectorized_models/#python-overheads","title":"Python overheads\u00b6","text":"<p>Summing a Python list of 1,000,000 numbers will be much slower than summing a NumPy array of 1,000,000 numbers. This is because NumPy is using compiled code that is not written in Python. Even if you wrote the code in C, it still might be slower than NumPy because NumPy is highly optimized.</p> <p>We can avoid using Python to iterate over a large collection of policies with vectorization.</p>"},{"location":"theory/vectorized_models/#initialization-conditions","title":"Initialization conditions\u00b6","text":"<p>The <code>t==0</code> condition on pols_if can cause a bug in aggregated results.</p> <pre>    def pols_if(self, t):\n        if t == 0:\n            return 1\n        return self.pols_if(t-1) - self.pols_death(t-1)\n</pre>"},{"location":"theory/vectorized_models/#running-multiple-scenarios-with-broadcasting","title":"Running multiple scenarios with broadcasting\u00b6","text":"<p>This is a bit advanced, but possibly useful in some situations. Recommended reading is the NumPy documentation on broadcasting.</p> <p>Typical models will operate on arrays of size <code>P</code> (policies). If you want to run multiple scenarios you can either</p> <ul> <li>Set up a loop over <code>S</code> scenarios</li> <li>Use broadcasting to operate on arrays with shape <code>(S, P)</code> without looping</li> </ul> <p>In our code, we demonstrate the broadcasting approach with a multiplicative factor we apply to mortality rates. Maybe we want to adjust the rates by factors of <code>[-.01, 0, .01]</code>.</p>"}]}